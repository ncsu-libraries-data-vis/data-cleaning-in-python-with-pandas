{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpbBQzdwReOX"
   },
   "source": [
    "# Data cleaning in Python with pandas\n",
    "\n",
    "##  Setup\n",
    "\n",
    "With this Google Colaboratory (Colab) notebook open, click the \"Copy to Drive\" button that appears in the menu bar. The notebook will then be attached to your own Google user account, so you can edit it in any way you like -- you can even take notes directly in the notebook.\n",
    "\n",
    "## Agenda\n",
    "\n",
    "1. **Guided instruction**: An instructor will work through the guided activity and teach concepts along the way.\n",
    "\n",
    "2. **Collaborative exercises**: After the guided portion of the workshop, we will have time to work collaboratively on provided exercises, ask questions, and discuss any concepts relevant to the materials. (Exercises can also be completed outside of the meeting time. A link to the filled version of this notebook containing all of the completed code is available at the end of the notebook under the section *Further resources* for reference)\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of our workshop today, we hope you'll understand what the pandas library is and be able to use pandas to load, explore, and manipulate data.\n",
    "\n",
    "### Today's Topics\n",
    "\n",
    "- Reading and writing data files\n",
    "\n",
    "- Exploring dataset characteristics\n",
    "\n",
    "- Manipulating a dataset (adding/removing/editing data)\n",
    "\n",
    "- Filtering a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YohJ7IZeTX31"
   },
   "source": [
    "### Using Jupyter Notebooks and Google Colaboratory\n",
    "\n",
    "Jupyter notebooks are a way to write and run Python code in an interactive way. They're quickly becoming a standard way of putting together data, code, and written explanations or visualizations into a single document and sharing that. There are a lot of ways that you can run Jupyter notebooks, including just locally on your computer, but we've decided to use Google's Colaboratory notebook platform for this workshop.  Colaboratory is “a Google research project created to help disseminate machine learning education and research.”  If you would like to know more about Colaboratory in general, you can visit the [Welcome Notebook](https://colab.research.google.com/notebooks/welcome.ipynb).\n",
    "\n",
    "Using the Google Colaboratory platform allows us to focus on learning and writing Python in the workshop rather than on setting up Python, which can sometimes take a bit of extra work depending on platforms, operating systems, and other installed applications. If you'd like to install a Python distribution locally, though, we're happy to help. Feel free to [get help from our graduate consultants](https://www.lib.ncsu.edu/dxl) or [schedule an appointment with Libraries staff](https://go.ncsu.edu/dvs-request)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diWLAlRBTsWT"
   },
   "source": [
    "## Guided Instruction\n",
    "\n",
    "**Content Warning:** This dataset contains information relating to violence towards animals. We understand that this may be distressing, and if you need to step away from the workshop we understand.\n",
    "\n",
    "In this section, we will work through examples using data from the [Federal Aviation Administration (FAA) Wildlife Strikes Database](https://wildlife.faa.gov/search). We have filtered the data to only include North Carolina.\n",
    "\n",
    "> \"The FAA Wildlife Strike Database contains records of reported wildlife strikes since 1990. Strike reporting is voluntary. Therefore, this database only represents the information we have received from airlines, airports, pilots, and other sources.\" - [FAA website](https://wildlife.faa.gov/home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsS2thybwJpY"
   },
   "outputs": [],
   "source": [
    "# Import the Pandas library as pd (callable in our code as pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77IUEVvoNhpJ"
   },
   "source": [
    "### Importing datasets\n",
    "\n",
    "We have prepared the data from the FAA website for this workshop. We will import those datasets into our notebook to use them for data analysis.\n",
    "\n",
    "- [Preview the CSV file (opens on GitHub)](https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_1990-1999.csv) - wildlife strike data from the years 1990-1999\n",
    "-[Preview the Excel file (this link will download the file)](https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2000-2009.xlsx?raw=true) - wildlife strike data from the years 2000-2009\n",
    "- [Preview the JSON file (opens on GitHub)](https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2010-2019.json) - wildlife strike data from the years 2010-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfCttfhqNhpS"
   },
   "outputs": [],
   "source": [
    "# Import the CSV file (wildlife strike data from the years 1990-1999)\n",
    "csv_file_url = 'https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_1990-1999.csv'\n",
    "\n",
    "\n",
    "# Print out the first five columns of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKTp-O2vNhpT"
   },
   "outputs": [],
   "source": [
    "# Import the Excel file (wildlife strike data from the years 2000-2009)\n",
    "xls_file_url = 'https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2000-2009.xlsx?raw=true'\n",
    "\n",
    "\n",
    "# Print out the first five columns of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DyV7h5pNhpU"
   },
   "outputs": [],
   "source": [
    "#Import the JSON file (wildlife strike data from the years 2010-2019)\n",
    "json_file_url = 'https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2010-2019.json'\n",
    "\n",
    "\n",
    "# Print out the first five columns of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ6_a__au-7z"
   },
   "source": [
    "### Reset DataFrame index labels\n",
    "The JSON file we imported does not include the column `INDX_NR`. Instead, these values are used as the index labels. We want this dataset to match the format of our other datasets, so we first need to reset the index using the DataFrame method `reset_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NexfOR1xPRcF"
   },
   "outputs": [],
   "source": [
    "# Reset the JSON DataFrame index and rename the column\n",
    "\n",
    "\n",
    "# Print out the first five columns of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rigiVVn3PpB"
   },
   "source": [
    "### Renaming column labels\n",
    "\n",
    "When we reset our index a new column `index` was created. Let's change the name of this column to `INDX_NR` to match our other datasets using the DataFrame `rename()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0AUqkC2OD5v"
   },
   "outputs": [],
   "source": [
    "# Rename the column we created\n",
    "\n",
    "\n",
    "# Print out the first five columns of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBKmROb2YK6_"
   },
   "source": [
    "### Concatenate the three DataFrames\n",
    "\n",
    "We want to be able to work with all of the data we have imported at once, so we need to pull all three DataFrames into one. They all have the same columns now, so we can concatenate them based on columns (similar to adding them together, one on top of another) using the pandas method `concat()`. We also need to consider the current index labels for each dataset. We will create a new zero-based integer index label for the concatenated dataset by passing the keyword argument `ignore_index=True` into the `concat()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEIc3jUzYNq5"
   },
   "outputs": [],
   "source": [
    "# Concatenate all the datasets into one\n",
    "\n",
    "\n",
    "# Print the shape (number of rows and columns) of the full DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnEJzysJ4N2h"
   },
   "source": [
    "### Merge DataFrames\n",
    "\n",
    "Our dataset includes a column of species IDs (`SPECIES_ID`) that consist of alpha-numeric codes that reference a specific species of animal. This code is not very helpful if we want to know the species name of an animal involved in a strike. Let's join our dataset with another dataset containing unique species IDs and species names using the shared column `SPECIES_ID` to generate a new column of data (`SPECIES`) containing species name using `merge()`. The URL to the dataset of species IDs and names is stored in the variable `species_names_file_url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTL942qP7-so"
   },
   "outputs": [],
   "source": [
    "# Load the species ID table (stored in a CSV file)\n",
    "species_names_file_url = 'https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_species_id_table.csv'\n",
    "\n",
    "\n",
    "# Print the loaded species ID table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLUpy4CaexGD"
   },
   "source": [
    "![Left join visual example](https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/Data_wrangling_with_Pandas/left-join.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0iqjbAUm9_9"
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame from a \"left\" join of the full dataset and the species\n",
    "# ID table based on the shared column \"SPECIES_ID\"\n",
    "\n",
    "\n",
    "# Print out the columns \"SPECIES\" and \"SPECIES_ID\" from the new merged dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcwpUDzN34rj"
   },
   "source": [
    "### Removing unnecessary columns\n",
    "\n",
    "We can reduce the size of our dataset by removing unnecessary columns of data using the DataFrame `drop()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1YZ_4pE7ZBU"
   },
   "outputs": [],
   "source": [
    "# Remove the \"STATE\", \"FAAREGION\", and \"COMMENT\" columns using \"drop()\"\"\n",
    "\n",
    "\n",
    "# Print out the first five records of the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLMysVq9yKYX"
   },
   "source": [
    "### Calculating new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEtlT-TaHjfA"
   },
   "source": [
    "#### Create a new column using an expression\n",
    "\n",
    "We may want to add a new column that is calculated based on other columns. In this example, we create a new column (`SINGLE_OR_MULTI_ENGINE`) of boolean values that tells us if the plane was a single-engine (TRUE) or a multi-engine (FALSE) plane using a comparison operator to test if the value in the column `NUM_ENGS` equals 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IL3zoS0cykQ8"
   },
   "outputs": [],
   "source": [
    "# Create a new column of boolean values indicating single- or multi-engine\n",
    "\n",
    "\n",
    "# Print out the new column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0etw8hbjI6QZ"
   },
   "source": [
    "#### Create a new column using `apply()`\n",
    "\n",
    "Sometimes you need to create a new column based on more complex manipulation of existing data. In this example, we use the `apply()` method to apply the function `calc_hour` along the rows in the column `TIME`. The `calc_hour` function parses an integer value of the hour from a string containing the time at which a strike occurred. We create a new column `HOUR` that contains a numerical representation of the hour in which a strike occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdtZZcTdJAHg"
   },
   "outputs": [],
   "source": [
    "# Define a function that takes a time string in the form \"HH:MM\" and returns the\n",
    "# hour as an integer if the hour value is valid\n",
    "def calc_hour(time_str):\n",
    "    hour = time_str.split(':')[0]\n",
    "    if hour.strip(' ') != '':\n",
    "        return int(hour)\n",
    "\n",
    "# Use the DataFrame apply() method to call calc_hour on the \"TIME\" column and\n",
    "# create a new column \"HOUR\" in our DataFrame\n",
    "\n",
    "\n",
    "# Print out the \"TIME\" and \"HOUR\" columns from our DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2RNfRsR13Mx"
   },
   "source": [
    "### Replace values in a column\n",
    "\n",
    "We can replace values in a column based on conditions, similar to \"find and replace.\" In this example, we make our new `SINGLE_OR_MULTI_ENGINE` column more descriptive by changing `True` into \" Single engine\" and `False` into \"Multi engine\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbS4YUYV17sE"
   },
   "outputs": [],
   "source": [
    "# Replace True or False values with new strings, \"Single engine\" or \"Multi engine\"\n",
    "\n",
    "\n",
    "# Print out the updated column of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtowpcFjYB98"
   },
   "source": [
    "### Filtering\n",
    "\n",
    "We can filter our data using conditional statements. This can help us remove unecessary rows of data or observe a specific range of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4lPRIIF9wKB"
   },
   "outputs": [],
   "source": [
    "# Filter the data to only see incidents that happened at night\n",
    "\n",
    "\n",
    "# Print out the filtered data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrY9dUg-YEjI"
   },
   "outputs": [],
   "source": [
    "# Filter the data to only see data from 2010 and after\n",
    "\n",
    "\n",
    "# Print out the filtered data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfhcH7Hv9-Zx"
   },
   "outputs": [],
   "source": [
    "# Filter the data to only see incidents from 2010 and after that happened at night\n",
    "\n",
    "\n",
    "# Print out the filtered data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUnZceXrWtpC"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Open work time\n",
    "You can use this time to ask questions, collaborate, or work on the following activities (on your own or in a group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAqsOIs2w89S"
   },
   "source": [
    "### Exercise 1: Rename column headers\n",
    "\n",
    "Rename the column `REG` to the more descriptive `AIRCRAFT_REGISTRATION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPib5An85g_f"
   },
   "outputs": [],
   "source": [
    "# Change the column name \"REG\" to \"AIRCRAFT_REGISTRATION\"\n",
    "\n",
    "\n",
    "# Print out the new DataFrame columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oh08mPHb-0RB"
   },
   "source": [
    "### Exercise 2: Remove unnecessary columns\n",
    "\n",
    "The are several columns of data that are not relevant for our analyses. Remove all columns related to engine and damage location (e.g., all the columns that begin with `ENG_`, `DAM_`, and `STR_`). A list of these column names is provided in the variable `drop_columns`.\n",
    "\n",
    "**Bonus:** See if you can derive the column names in the list `drop_columns` from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0u9pN2ggWn7"
   },
   "outputs": [],
   "source": [
    "# A list of column names to remove from the DataFrame\n",
    "drop_columns = ['ENG_1_POS', 'ENG_2_POS', 'ENG_3_POS', 'ENG_4_POS', 'STR_RAD',\n",
    "                'DAM_RAD', 'STR_WINDSHLD', 'DAM_WINDSHLD', 'STR_NOSE',\n",
    "                'DAM_NOSE', 'STR_ENG1', 'DAM_ENG1', 'STR_ENG2', 'DAM_ENG2',\n",
    "                'STR_ENG3', 'DAM_ENG3', 'STR_ENG4', 'DAM_ENG4', 'STR_PROP',\n",
    "                'DAM_PROP', 'STR_WING_ROT', 'DAM_WING_ROT', 'STR_FUSE',\n",
    "                'DAM_FUSE', 'STR_LG', 'DAM_LG', 'STR_TAIL', 'DAM_TAIL',\n",
    "                'STR_LGHTS', 'DAM_LGHTS', 'STR_OTHER', 'DAM_OTHER']\n",
    "\n",
    "# Remove unnecessary columns\n",
    "\n",
    "\n",
    "# Print out the new DataFrame columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8TSrmwW868c"
   },
   "source": [
    "### Exercise 3: Filter out unnecessary rows\n",
    "\n",
    "Our dataset should only contain data from the years 1990-2019. Remove any rows of data that contain strikes that occurred outside of this year range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HbTYcuL9Xgj"
   },
   "outputs": [],
   "source": [
    "# Filter out rows of data that contain strikes that occurred outside of the year\n",
    "# range 1990-2019\n",
    "\n",
    "\n",
    "# Print out the new filtered DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hc8TS8Xar8O"
   },
   "source": [
    "### Exercise 4: Join airline operator names with the full dataset\n",
    "\n",
    "Our dataset contains a column of airline operator IDs (`OPID`). These IDs correspond with airline operator names (e.g., Delta Airlines, Military, United Airlines, etc.). We have another dataset that contains arline operator IDs (in a column named `OPID`) and the corresponding airline operator name (in a column named `OPERATOR`). The URL to this dataset is stored in the variable `op_name_file_url`. Load this dataset and use a left join to merge the operator name with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSQmchxx-BFU"
   },
   "outputs": [],
   "source": [
    "# URL to the CSV file containing unique airline operator IDs and names\n",
    "op_name_file_url = 'https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_operator_id_table.csv?raw=true'\n",
    "\n",
    "# Load the operator ID and name dataset into a DataFrame\n",
    "\n",
    "\n",
    "# Join airline operator names to the full dataset using matching operater IDs\n",
    "\n",
    "\n",
    "# Print out the columns \"OPID\" and \"OPERATOR\" from the new merged DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etgjBVCQoGWv"
   },
   "source": [
    "### Exercise 5: Create a new column containing month names\n",
    "\n",
    "Our dataset currently contains a column of integer values representing the month number in which a strike occurred (1-12). It would be helpful to have a column containing the month name (e.g., January, February, etc.). Calculate a new column labeled `MONTH_NAME` containing the month name in which a stike occurred.\n",
    "\n",
    "**TIP:** There are multiple ways you could consider creating this new column (e.g., using `replace()` or `apply()`), but it might be helpful to have a way to map month numbers (1-12) to month names (January - December) (e.g., a list or dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1ti8X6sYLvM"
   },
   "outputs": [],
   "source": [
    "# Create a new column \"MONTH_NAME\" containing month names in which a strike occurred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_dY4wqNdRSD"
   },
   "source": [
    "## Further resources\n",
    "\n",
    "### Filled version of this notebook\n",
    "\n",
    "[Python Open Labs Week 2 filled notebook](https://colab.research.google.com/github/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/Data_wrangling_with_Pandas/Python_Open_Labs_Week2_filled.ipynb) - a version of this notebook with all code filled in for the guided activity and exercises.\n",
    "\n",
    "### Learning resources\n",
    "\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html) - a free, online version of Jake VanderPlas' introduction to data science with Python, includes a chapter on data manipulation with pandas.\n",
    "- [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html) - a website providing a great overview of conducting data science with Python including pandas.\n",
    "\n",
    "### Finding help with pandas\n",
    "\n",
    "The [Pandas website](https://pandas.pydata.org/) and [online documentation](http://pandas.pydata.org/pandas-docs/stable/) are useful resources, and of course the indispensible [Stack Overflow has a \"pandas\" tag](https://stackoverflow.com/questions/tagged/pandas).  There is also a (much younger, much smaller) [sister site dedicated to Data Science questions that has a \"pandas\" tag](https://datascience.stackexchange.com/questions/tagged/pandas) too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAAF-mLyRqeE"
   },
   "source": [
    "## Evaluation Survey\n",
    "Please, spend 1 minute answering these questions that help improve future workshops.\n",
    "\n",
    "https://go.ncsu.edu/dvs-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6Sj-7OYR5JL"
   },
   "source": [
    "## Credits\n",
    "\n",
    "This workshop was created by Walt Gurley and Claire Cahoon, adapted from previous workshop materials by Scott Bailey and Simon Wiles, of Stanford Libraries."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Python_Open_Labs_Week2.ipynb",
   "provenance": [
    {
     "file_id": "12Rme5FLxDFpTFAldfgsleGG6eyXw2ewl",
     "timestamp": 1615288363335
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
